{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672ab078-ae9e-47db-8e97-2819cc351dab",
   "metadata": {},
   "source": [
    "# Cell segmentation with Cellpose\n",
    "\n",
    "In cell biology, identifying cells in microscopic images is a critical step for quantifying many parameters, such as cell death, protein expression, activity, and more. Traditionally, this identification has been done visually by experimenters. However, with recent advancements in computer vision algorithms, this process has become more automated and efficient.\n",
    "\n",
    "In this **notebook**, I use **Cellpose** for cell segmentation of two-photon calcium recordings. Specifically, I use the latest version developed by Stringer, Pachitariu, and colleagues, **Cellpose-SAM**, which integrates the foundation model **Segment Anything Model (SAM)** ([Kirillov et al., 2023](https://openaccess.thecvf.com/content/ICCV2023/html/Kirillov_Segment_Anything_ICCV_2023_paper.html)) into Cellpose. The original Cellpose used a neural network (U-Net) to predict spatial gradients and then produce masks ([Stringer et al., 2021](https://www.nature.com/articles/s41592-020-01018-x)), whereas Cellpose-SAM adapts SAM's transformer-based architecture to enhance generalization across diverse imaging conditions. For details, see [Pachitariu et al., 2025](https://www.biorxiv.org/content/10.1101/2025.04.28.651001v1.full).\n",
    "\n",
    "**Cellpose** is [well-documented](https://cellpose.readthedocs.io/en/latest/), actively maintained (see the [GitHub repository](https://github.com/MouseLand/cellpose)), and, most importantly, easy to use ([example notebook](https://github.com/MouseLand/cellpose/blob/main/notebooks/run_Cellpose-SAM.ipynb)). Among other outputs, it returns **masks** and regions of interest (ROIs), which can be exported for use in **ImageJ** or Python (ImageJROI).\n",
    "\n",
    "I have tested several two-photon calcium recordings without training the model, with good results. Post-hoc filtering (e.g., signal-to-noise criteria) can help remove noisy traces and artifacts. In this notebook, I show a simple example of how to apply Cellpose to two short time-series recordings (see below) to calculate and plot the **ΔF/F** traces from the masks identified by Cellpose.\n",
    "\n",
    "**References**:\n",
    "- [Cellpose-SAM website](https://huggingface.co/spaces/mouseland/cellpose) To process images online.\n",
    "- Pachitariu, M., Rariden, M., & Stringer, C. (2025). Cellpose-SAM: superhuman generalization for cellular segmentation. [bioRxiv](https://www.biorxiv.org/content/10.1101/2025.04.28.651001v1.full).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac038c65-f88b-4438-a4c3-50cefabcbae9",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "**IMPORTANT**: You first need to install [cellpose](https://github.com/MouseLand/cellpose) to use this notebook. Please read the up-to-date instructions on the [cellpose GitHub](https://github.com/MouseLand/cellpose/blob/main/README.md/#Installation). In brief, you need:\n",
    "1. Open an anaconda prompt or command prompt which has `conda` for python 3 in the path\n",
    "2. Create a new environment: `conda create --name cellpose python=3.10`\n",
    "3. Activate the new environment: `conda activate cellpose`\n",
    "4. Install cellpose: `python -m pip install cellpose[gui]`(with the user interface) or `python -m pip install cellpose` (without the user interface).\n",
    "5. Install the following packages to run this notebook: `python -m pip install jupyterlab matplotlib pandas`\n",
    "\n",
    "Note: To use the GPU, you need to install the drivers and the CUDA libraries. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a497415a-f35a-4a9a-9397-a854c6523654",
   "metadata": {},
   "source": [
    "# Example data: two-photon calcium imaging\n",
    "\n",
    "Example data come from two-photon calcium imaging recordings of the visual cortex in neonatal mice (see [example video](https://youtu.be/VtAjtu00oKE)). I extracted 15-seconds segments from recordings that were previously motion-corrected using the package [CaImAn](https://caiman.readthedocs.io/en/latest/CaImAn_Tips.html), and were downsampled to a frequency of 7-10 Hz to reduce file size. \n",
    "* `2P_GCaMP8m`. Recorded with the GCaMP8m calcium sensor ([Zhang et al., 2023](https://www.nature.com/articles/s41586-023-05828-9)).\n",
    "* `2P_somaFRCaMPi`. Recorded with the somaFRCaMPi calcium sensor ([Zhou et al., 2025](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3003048)).\n",
    "\n",
    "For a very accessible and comprehensive introduction to two-photon calcium imaging, I recommend the primer from Grienberger et al., 2022. The two images below are from this paper.\n",
    "\n",
    "### Two-photon calcium imaging\n",
    "\n",
    "Briefly, calcium imaging makes use of **fluorescent calcium indicators**, which consist of a protein (e.g., calmodulin) that binds calcium ions (Ca²⁺) and is linked to a fluorescent protein. When neurons are active (i.e., fire action potentials), voltage-gated calcium channels and NMDA receptors open, allowing Ca²⁺ to enter the cell. Calcium ions then bind to the calcium indicator inside the neuron, increasing fluorescence emission. Since calcium levels can increase up to 100-fold during neuronal activity, the signal-to-noise ratio of calcium imaging is high.\n",
    "\n",
    "<img src=\"../Figures/calcium_sensor_indicators_grienberger_et_al_2022.png\" width=\"700\"/>\n",
    "\n",
    "Although the calcium dynamics are slower than action potentials, calcium imaging has become a useful proxy for investigating how neural activity correlates with behavior, pharmacological interventions, and brain disorders. In fact, since the development of **genetically encoded calcium indicators (GECI)** in 2001 ([Nakai et al., 2001](https://pubmed.ncbi.nlm.nih.gov/11175727/)) and, especially, the watershed release of GCaMP6 ([Chen et al., 2013](https://www.nature.com/articles/nature12354)), modern neuroscience can no longer be understood, for better or worse, without calcium imaging. The calcium indicator toolkit now includes dozens of GECIs with different affinities, kinetics, and colors ([Shen et al., 2020](https://www.sciencedirect.com/science/article/pii/S0168010220300389), [Addgene](https://blog.addgene.org/aav-encoded-calcium-sensors)).\n",
    "\n",
    "The typical pipeline of a **two-photon calcium imaging** experiment in mice for analyzing neuronal activity is as follows:\n",
    "1. Expression of calcium sensors. GECIs can be expressed across the brain or in very specific subpopulations of neurons using, for example, [viral vectors](https://spikesandbursts.wordpress.com/2024/12/30/adeno-associated-viruses-almost-always-deliver/).\n",
    "2. Cranial window and two-photon microscopy. A cranial window is created to provide visual access to the brain, and two-photon microscopy is used to image the fluorescent signal of calcium indicators, even in deep brain structures. This allows imaging of dozens to hundreds of neurons simultaneously. For a detailed overview of two-photon microscopy, see [Helmchen and Denk, 2005](https://microscopist.co.uk/files/wp-content/uploads/2017/04/helmchen2005.pdf) and [Svoboda and Yasuda, 2006](https://www.sciencedirect.com/science/article/pii/S0896627306004119).\n",
    "3. Signal analysis. Recorded movies are then analyzed to extract fluorescence signals and other measures of neuronal activity.\n",
    "\n",
    "<img src=\"../Figures/two_photon_calcium_imaging_grienberger_et_al_2022.png\" width=\"1000\">\n",
    "\n",
    "**Further reading**\n",
    "- Ali and Kwan, 2019. Interpreting in vivo calcium signals from neuronal cell bodies, axons, and dendrites: a review. [Link](https://pmc.ncbi.nlm.nih.gov/articles/PMC6664352/).\n",
    "- Chen et al., 2013. Ultrasensitive fluorescent proteins for imaging neuronal activity. [Link](https://www.nature.com/articles/nature12354). \n",
    "- Grienberger et al., 2022. Two-photon calcium imaging of neuronal activity. [Link](https://pmc.ncbi.nlm.nih.gov/articles/PMC10732251/)\n",
    "- Grienberger and Konnerth, 2012. Imaging Calcium in Neurons. [Link](https://doi.org/10.1016/j.neuron.2012.02.011). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84edb7f-e317-479f-bc12-d9743a512183",
   "metadata": {},
   "source": [
    "# Import the libraries\n",
    "\n",
    "Note: Once cellpose is installed, you can clone the repository, and run all the cells of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed26fd3-ae5a-404a-9184-a89399b1a005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v4.0.1! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n",
      "creating new log file\n",
      "2025-05-12 10:53:09,857 [INFO] WRITING LOG OUTPUT TO C:\\Users\\cabrera\\.cellpose\\run.log\n",
      "2025-05-12 10:53:09,857 [INFO] \n",
      "cellpose version: \t4.0.2 \n",
      "platform:       \twin32 \n",
      "python version: \t3.10.16 \n",
      "torch version:  \t2.5.1\n",
      "2025-05-12 10:53:09,857 [INFO] >>>> using CPU\n",
      "2025-05-12 10:53:09,862 [INFO] >>>> using CPU\n",
      "2025-05-12 10:53:10,917 [INFO] >>>> loading model C:\\Users\\cabrera\\.cellpose\\models\\cpsam\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Cellpose functions\n",
    "from cellpose import models, core, io, utils, plot\n",
    "from cellpose.utils import masks_to_outlines\n",
    "\n",
    "io.logger_setup() # run this to get printing of progress\n",
    "model = models.CellposeModel(gpu=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib widget  # Interactive plots\n",
    "plt.rcParams['svg.fonttype'] = 'none' # To generate editable text in saved *.svg plots\n",
    "plt.close('all')\n",
    "\n",
    "# Import ROIs from ImageJ\n",
    "from roifile import ImagejRoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3d674-0669-4ea5-b1fa-05f9dfd484f8",
   "metadata": {},
   "source": [
    "# Create the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c77002a-e0d5-4eaa-a0a7-a8132204a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = 'cellpose_segmentation_2p'\n",
    "\n",
    "# Data path to 'Data_example' folders. Change accordingly to your data structure.\n",
    "data_path = os.path.dirname(os.getcwd())  # Moves one level up from the current directory\n",
    "\n",
    "# Change the folder names accordingly\n",
    "paths = {'data': data_path,\n",
    "         'raw_data':  f'{data_path}/Data_examples/{notebook_name}/',\n",
    "         'processed_data': f'{data_path}/Processed_data_examples/{notebook_name}/',\n",
    "         'analysis': f'{data_path}/Analysis_examples/{notebook_name}/',         \n",
    "         'plots': f'{data_path}/Analysis_examples/{notebook_name}/Plots/'}\n",
    "\n",
    "# Make folders if they do not exist yet\n",
    "for path in paths.values():\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd7531-f871-4456-9216-69301a9f8d6a",
   "metadata": {},
   "source": [
    "# Segmentation parameters\n",
    "\n",
    "More information about parameters [here](https://cellpose.readthedocs.io/en/latest/settings.html). Default parameters are already quite good, but tuning them can help reduce \"false positives.\" For further fine-tuning, the authors recommend using your own recordings to train the model, which should improve accuracy (see [how](https://github.com/MouseLand/cellpose/blob/main/docs/train.rst)).\n",
    "\n",
    "- **flow_threshold**: Maximum allowed error of the flows for each mask. **Default: 0.4**. Increase this threshold if Cellpose is not returning as many masks as expected (or turn off completely with 0.0). Decrease it if Cellpose returns too many ill-shaped masks.\n",
    "- **cellprob_threshold**: Probability threshold that a detected object is a cell. **Default: 0.0**. Decrease this threshold if Cellpose is not returning enough masks or the masks are too small. Increase it if Cellpose returns too many ROIs, particularly from dim areas.\n",
    "- **tile_norm_blocksize**: Size of the blocks used for image normalization. **Default: 0.0** (entire image normalized together). Set to 100–200 pixels if brightness is very inhomogeneous across the image.\n",
    "- **niter**: **Default: None or 0**. Sets the number of iterations proportional to the ROI diameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f19552-be7e-4c27-a4b1-9be1f2f1cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellpose SAM Parameters\n",
    "flow_threshold = 0.2  # Maximum allowed error of the flows for each mask\n",
    "cellprob_threshold = 0.5  # Determines proability that a detected object is a cell\n",
    "tile_norm_blocksize = 0   # Size of blocks used for normalizing the image\n",
    "niter = None  # Number of iterations. Default is proportional to the ROI diameter.\n",
    "\n",
    "# Create a dictionary\n",
    "cellpose_params = {\n",
    "    \"flow_threshold\": flow_threshold,\n",
    "    \"cellprob_threshold\": cellprob_threshold,\n",
    "    \"tile_norm_blocksize\": tile_norm_blocksize,\n",
    "    \"niter\": niter}\n",
    "\n",
    "# Save the dictionary to a text file\n",
    "with open(f\"{paths['analysis']}{notebook_name}_cellpose_params.txt\" , \"w\") as f:\n",
    "    for key, value in cellpose_params.items():\n",
    "        f.write(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d552ab-0db4-48b1-86b8-d34d421dd26f",
   "metadata": {},
   "source": [
    "# Loop for two-photon calcium recordings\n",
    "\n",
    "This is an example loop that you can adapt to your paths and datasets. After running cellpose, it uses the cell masks to extract and plot the ΔF/F for each mask (∼neuron). For a comprehensive guide on ΔF/F calculation in calcium imaging, see this in-depth article by [Peter Rupprecht](https://www.scientifica.uk.com/learning-zone/how-to-compute-%CE%B4f-f-from-calcium-imaging-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fef49e0-f000-4991-880c-58eb0928fc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-12 10:53:11,674 [INFO] reading tiff with 113 planes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 113/113 [00:00<00:00, 1596.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with deltaF_F traces: C:\\Users\\cabrera\\Documents\\GitHub\\neuro-notebook-templates/Analysis_examples/cellpose_segmentation_2p/2P_GCaMP8m_traces.csv\n",
      "Traces plot: C:\\Users\\cabrera\\Documents\\GitHub\\neuro-notebook-templates/Analysis_examples/cellpose_segmentation_2p/2P_GCaMP8m_traces.png\n",
      "2025-05-12 10:53:55,106 [INFO] reading tiff with 113 planes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 113/113 [00:00<00:00, 2724.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with deltaF_F traces: C:\\Users\\cabrera\\Documents\\GitHub\\neuro-notebook-templates/Analysis_examples/cellpose_segmentation_2p/2P_somaFRCaMPi_traces.csv\n",
      "Traces plot: C:\\Users\\cabrera\\Documents\\GitHub\\neuro-notebook-templates/Analysis_examples/cellpose_segmentation_2p/2P_somaFRCaMPi_traces.png\n",
      "CPU times: total: 6min 52s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for dirpath, dirnames, files in os.walk(paths['raw_data']):\n",
    "    for file in files:\n",
    "        if file.endswith('.tif'):\n",
    "            file_path = f\"{dirpath}/{file}\"\n",
    "            filename = os.path.splitext(file)[0]\n",
    "\n",
    "            # Read image and calculate average image\n",
    "            stack = io.imread(file_path)\n",
    "            stack_avg = stack.mean(axis=0)\n",
    "\n",
    "            # Run Cellpose to segment neurons\n",
    "            masks, flows, styles = model.eval(\n",
    "                stack_avg,\n",
    "                batch_size=32,\n",
    "                flow_threshold=flow_threshold,\n",
    "                cellprob_threshold=cellprob_threshold,\n",
    "                normalize={\"tile_norm_blocksize\": tile_norm_blocksize},\n",
    "                niter=niter\n",
    "            )\n",
    "\n",
    "            # Save masks as both image and numpy array\n",
    "            masks_path = f\"{paths['analysis']}{filename}_masks.tif\"\n",
    "            masks_img = io.imsave(masks_path, masks.astype('uint16'))\n",
    "            np.save(f\"{paths['analysis']}{filename}_masks.npy\", masks)\n",
    "\n",
    "            # Save ROIs for ImageJ (open with ImageJ ROI manager)\n",
    "            io.save_rois(masks, f\"{paths['analysis']}{filename}.zip\")  \n",
    "\n",
    "            # Segmentation images  \n",
    "            fig = plt.figure(figsize=(12,5))\n",
    "            plot.show_segmentation(fig, stack_avg, masks, flows[0])\n",
    "            plt.tight_layout()\n",
    "            fig.savefig(f\"{paths['analysis']}{filename}_segmentation.svg\", dpi=300)\n",
    "            plt.close(fig)    \n",
    "\n",
    "            # Extract calcium traces from cell masks\n",
    "            cell_masks = np.unique(masks)  # Get all unique region labels in the masks\n",
    "            cell_masks = cell_masks[cell_masks != 0]  # Ignore 0 values\n",
    "               \n",
    "            traces = []\n",
    "            for mask in cell_masks:\n",
    "                cell_mask = (masks == mask)  # Binary mask for the current cell\n",
    "                mask_pixels = stack[:, cell_mask]  # Get mask pixels over all time frames\n",
    "                    \n",
    "                trace = np.nanmean(mask_pixels, axis=1)  # Calculate mean of this cell over time\n",
    "            \n",
    "                # DeltaF/F calculation\n",
    "                f0 = np.median(trace)  # Or using percentiles\n",
    "                delta_f = (trace - f0) / f0 * 100 if f0 != 0 else np.zeros_like(trace)\n",
    "                traces.append(delta_f)\n",
    "\n",
    "            # Save traces to a dataframe\n",
    "            df_index = np.arange(stack.shape[0]) + 1  # Frames\n",
    "            df = pd.DataFrame(np.vstack(traces).T, \n",
    "                              index=df_index, \n",
    "                              columns=[f'n_{mask}' for mask in cell_masks])\n",
    "\n",
    "            csv_path = f\"{paths['analysis']}{filename}_traces.csv\"\n",
    "            df.to_csv(csv_path)\n",
    "            print(f\"Dataframe with deltaF_F traces: {csv_path}\")\n",
    "\n",
    "            # Plot deltaF/F traces (adapt as you wish to suit your preferences)\n",
    "            n_cell_masks = len(cell_masks)  # One trace per row\n",
    "            fig, axes = plt.subplots(n_cell_masks, 1, figsize=(4, 0.15 * n_cell_masks), \n",
    "                                     sharex=True, sharey=True)\n",
    "            if n_cell_masks == 1:\n",
    "                axes = [axes]  # In case only one neuron is detected\n",
    "\n",
    "            for ax, trace, cell_mask in zip(axes, traces, cell_masks):\n",
    "                ax.plot(df_index, trace, color='black', linewidth=0.5)\n",
    "                ax.set_ylabel(f'n_{cell_mask}', rotation=0, labelpad=10, va='center')\n",
    "                # Remove spines and tick to make the plot cleaner\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                ax.spines['left'].set_visible(False)\n",
    "                ax.spines['bottom'].set_visible(False)\n",
    "                ax.set_yticks([])\n",
    "                ax.set_xticks([])\n",
    "\n",
    "            plt.subplots_adjust(hspace=0.01, left=0.1, right=0.9, top=0.9, bottom=0.01)\n",
    "            plt.tight_layout(pad=0.5)\n",
    "            trace_plot_path = f\"{paths['analysis']}{filename}_traces.png\"  # or svg\n",
    "            fig.savefig(trace_plot_path, dpi=300)\n",
    "            plt.close(fig)\n",
    "            print(f\"Traces plot: {trace_plot_path}\")\n",
    "\n",
    "            del stack  # Remove stack from memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c2828-b3b2-4411-97b2-1a880ab7787e",
   "metadata": {},
   "source": [
    "# Import the cellpose ROIs\n",
    "\n",
    "Exported ROIs can be opened in ImageJ or in Python with ImageJROI ([read documentation](https://github.com/cgohlke/roifile)). Below is just an example of how to load the file. Alternatively, you can load the NumPy array with the masks, which may be easier for extracting traces if you want to reuse them in another script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f15fca8-9c9e-49e8-8413-f76879895a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, files in os.walk(paths['analysis']):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            file_path = f\"{dirpath}/{file}\"\n",
    "            filename = os.path.splitext(file)[0]\n",
    "            rois_path = f\"{paths['analysis']}{filename}.zip\"\n",
    "            # Use ImagejRois to load ROIs from file\n",
    "            rois = ImagejRoi.fromfile(rois_path)  \n",
    "            for i, roi in enumerate(rois):\n",
    "                roi.coordinates  # Example to get coordinates from each ROI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
