{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf7099d-7f35-49cc-abe2-d4574ffa2275",
   "metadata": {},
   "source": [
    "# Pre-processing of time-series\n",
    "\n",
    "Time series are measurements that are indexed according to time. For example, electrophysiological recordings or live fluorescence signals. Depending on the goal and the recording, pre-processing or processing of time series data might include: detrending, filtering and/or smoothing. \n",
    "\n",
    "Save each step/trace separately, and save the parameters applied to each trace. For example, save them as [Numpy file](https://numpy.org/doc/stable/reference/generated/numpy.save.html).\n",
    "\n",
    "This notebook contains some simple functions to test and compare different ways for pre-processing time series. The links below contain more information and resources.\n",
    "\n",
    "**Time-series**\n",
    "* [A Very Short Course on Time Series Analysis](https://bookdown.org/rdpeng/timeseriesbook/) by Roger D. Peng.\n",
    "\n",
    "**Filtering**\n",
    "* [Filtering EEG Data](https://neuraldatascience.io/7-eeg/erp_filtering.html?highlight=power+spectra) from [Neural Data Science in Python](https://neuraldatascience.io/intro.html) by Aaron J. Newman.\n",
    "* [Filtering Field Data](https://mark-kramer.github.io/Case-Studies-Python/06.html) from [Case studies in Neural Data Analysis](https://mark-kramer.github.io/Case-Studies-Python/intro.html) by Mark Kramer and Uri Eden.\n",
    "* [Signal processing](https://github.com/BIPN162/Materials/blob/master/15-SignalProcessing.ipynb) from [Neural Data Science course](https://github.com/BIPN162/Materials/tree/master) by Ashley Juavinett.\n",
    "\n",
    "**Smoothing**\n",
    "* [A brief introduction to time series smoothing](https://medium.com/@jodancker/a-brief-introduction-to-time-series-smoothing-4f7ed61f78e1) by Jonte Dancker. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a3395c-8602-44e4-a926-27982d781f6c",
   "metadata": {},
   "source": [
    "# Example data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217204ce-ed19-40c4-9d37-19a86d3b98d1",
   "metadata": {},
   "source": [
    "Time-series data from widefield recordings of fluorescent sensors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb36fd8-b6f4-4b42-8d0c-f5810430778b",
   "metadata": {},
   "source": [
    "# Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b5e3e-edae-4080-9561-d9645f6f4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Interactive plots (comment out if needed)\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display\n",
    "# #For Jupyter Lab:\n",
    "# %matplotlib widget\n",
    "\n",
    "# Scipy libraries\n",
    "\n",
    "from scipy import signal, stats\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62dd35d-63e0-49a9-a3d8-35df8bb815ce",
   "metadata": {},
   "source": [
    "# Paths\n",
    "\n",
    "Change the paths and folder names according to your data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc5d44-1eae-49af-bf17-4db12ca5fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = 'time_series_preprocessing'\n",
    "\n",
    "# Data path to 'Data_example' folders. Change accordingly to your data structure.\n",
    "data_path = os.path.dirname(os.getcwd())  # Moves one level up from the current directory\n",
    "\n",
    "# Change the folder names accordingly\n",
    "paths = {'data': data_path,\n",
    "         'raw_data':  f'{data_path}/Data_examples/{notebook_name}/',\n",
    "         'processed_data': f'{data_path}/Processed_data_examples/{notebook_name}/',\n",
    "         'analysis': f'{data_path}/Analysis_examples/{notebook_name}/',         \n",
    "         'plots': f'{data_path}/Analysis_examples/{notebook_name}/Plots/'}\n",
    "\n",
    "# Make folders if they do not exist yet\n",
    "for path in paths.values():\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a75cc-37f0-40cf-98a2-a51eac644270",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3171911-f0ff-4f68-8ebe-be95e8f4a4fc",
   "metadata": {},
   "source": [
    "## Detrend\n",
    "\n",
    "In detrending, we try to remove some aspects that are distorting the signal and we assume (or evaluate) are not part of our biological variable of interest. For example: rundown due to intracellular solution, photobleaching, baseline instability, etc. Consider that the applied detrend method has to be logically related to the external confound you would like to remove. \n",
    "\n",
    "As example, this function applies some commonly detrend methods for electrophysiology and fluorescent sensor traces. From subtracting the average because the baseline is not zero, to non-linear fitting for unstable baselines. Simplify or extend the below function according to your analysis. Documentation:\n",
    "\n",
    "* Subtract the average: E.g. `x - np.mean(x)`, median, median of lowest values, etc\n",
    "* [Scipy linear detrend](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.detrend.html)\n",
    "* [Numpy Differencing](https://numpy.org/doc/stable/reference/generated/numpy.diff.html)\n",
    "* [Scipy exponential decay](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) \n",
    "* Model fitting (polynomial): https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db19a4-4580-4f5c-b506-0eef928d31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_detrend(trace_data, timestamps, method='exponential', window=None):\n",
    "    \"\"\"\n",
    "    Detrend a time-series trace using linear, exponential, polynomial fit, rolling linear correction, median subtraction or lowess.\n",
    "        - Scipy linear detrend: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.detrend.html\n",
    "        - Scipy exponential fit: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.detrend.html\n",
    "        - Numpy polynomial fit: https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html\n",
    "        - Rolling baseline correction with scipy linear regression: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html\n",
    "        - Numpy median subtraction: https://numpy.org/doc/stable/reference/generated/numpy.median.html\n",
    "        - Locally Weighted Scatterplot Smoothing: https://www.statsmodels.org/devel/generated/statsmodels.nonparametric.smoothers_lowess.lowess.html\n",
    "\n",
    "    Args:\n",
    "        trace_data (numpy array): The data trace to be detrended.\n",
    "        timestamps (numpy array): The time array corresponding to the trace.\n",
    "        method (str): Detrending methods ('linear', 'exponential', 'polyfit', 'rolling_linear', 'median', 'lowess').\n",
    "        window (int, optional): The window size for rolling linear correction or other methods (optional).\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Detrended trace.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert pandas Series to numpy array if needed\n",
    "    if isinstance(trace_data, pd.Series):\n",
    "        trace_data = trace_data.to_numpy()\n",
    "        timestamps = timestamps.to_numpy()\n",
    "    \n",
    "    if method == 'linear':\n",
    "        if window:\n",
    "            return np.concatenate([\n",
    "                signal.detrend(trace_data[i:i + window], type='linear') \n",
    "                for i in range(0, len(trace_data), window)\n",
    "            ])\n",
    "        else:\n",
    "            return signal.detrend(trace_data, type='linear')\n",
    "        \n",
    "    elif method == 'exponential':\n",
    "        if window:\n",
    "            exp_detrend_trace = []\n",
    "            for i in range(0, len(trace_data), window):\n",
    "                trace_segment = trace_data[i:i + window]\n",
    "                time_segment = timestamps[i:i + window]\n",
    "                initial_a = 20  \n",
    "                initial_b = 0.005\n",
    "                popt, _ = curve_fit(lambda t, a, b: a * np.exp(-t * b), \n",
    "                                    time_segment, trace_segment, \n",
    "                                    p0=(initial_a, initial_b))\n",
    "                a, b = popt\n",
    "                exp_fit = a * np.exp(-time_segment * b)\n",
    "                exp_detrend_trace.append(trace_segment - exp_fit)\n",
    "            return np.concatenate(exp_detrend_trace)\n",
    "        \n",
    "        else:\n",
    "            initial_a = 20  \n",
    "            initial_b = 0.005  \n",
    "            popt, _ = curve_fit(lambda t, a, b: a * np.exp(-t * b), \n",
    "                                timestamps, trace_data, \n",
    "                                p0=(initial_a, initial_b))\n",
    "            a, b = popt\n",
    "            exp_fit = a * np.exp(-timestamps * b)\n",
    "            exp_detrend_trace = trace_data - exp_fit\n",
    "            return exp_detrend_trace\n",
    "    \n",
    "    elif method == 'polyfit':\n",
    "        if window:\n",
    "            polyfit_detrend = []\n",
    "            for i in range(0, len(trace_data), window):\n",
    "                trace_segment = trace_data[i:i + window]\n",
    "                time_segment = timestamps[i:i + window]\n",
    "                polyfit = np.poly1d(np.polyfit(time_segment, trace_segment, 6))\n",
    "                polyfit_len = polyfit(np.linspace(0, time_segment[-1], len(trace_segment)))\n",
    "                polyfit_detrend.append(trace_segment - polyfit_len)\n",
    "            return np.concatenate(polyfit_detrend)\n",
    "        else:\n",
    "            polyfit = np.poly1d(np.polyfit(timestamps, trace_data, 6))\n",
    "            polyfit_len = polyfit(np.linspace(0, timestamps[-1], len(trace_data)))\n",
    "            polyfit_detrend_trace = trace_data - polyfit_len\n",
    "            return polyfit_detrend_trace\n",
    "\n",
    "    elif method == 'rolling_linear':\n",
    "        if window is None:\n",
    "            raise ValueError(\"Provide value for 'window'\")\n",
    "        n = np.floor(len(trace_data) / window)\n",
    "        fit_trace = trace_data[: int(n * window)]\n",
    "        x_bin = np.arange(0, len(fit_trace), window) + window / 2\n",
    "        folded_trace = fit_trace.reshape((window, -1), order='F')\n",
    "        medians = np.median(folded_trace, axis=0)\n",
    "        a, b = stats.linregress(x_bin, medians)[:2]\n",
    "        rolling_linear_trace = trace_data - (a * np.arange(len(trace_data)) + b)\n",
    "        return rolling_linear_trace\n",
    "    \n",
    "    elif method == 'median':\n",
    "        median_value = np.median(trace_data)\n",
    "        median_detrend_trace = trace_data - median_value\n",
    "        return median_detrend_trace\n",
    "    \n",
    "    elif method == 'lowess':\n",
    "        # Apply LOESS/LOWESS smoothing\n",
    "        smoothed = lowess(trace_data, timestamps, frac=window/np.ptp(timestamps))\n",
    "        trend = smoothed[:, 1]\n",
    "        return trace_data - trend\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Choose a valid 'method'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b176346-431e-44e8-a04a-bf35117f7054",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "A filter operates on digitized data to either pass or reject a defined frequency range. All filters distort the signal to some degree, and each one has different attenuation limitations and artifacts.\n",
    "\n",
    "Common filters for **time-domain** biological data include:\n",
    "* **Bessel** filter. [Documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.bessel.html) \n",
    "* **Gaussian** filter. [Documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter1d.html)\n",
    "\n",
    "Common filters for **frequency-domain** applications include:\n",
    "* **Butterworth** filter (non-constant delay characteristics). [Documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html).\n",
    "\n",
    "Apply the filter to the signal: `filtfilt` (zero-phase filtering). [Documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.filtfilt.html)\n",
    "\n",
    "**References** \n",
    "* Widmann et al., 2015. [Digital filter design for electrophysiological data – a practical approach](https://www.sciencedirect.com/science/article/pii/S0165027014002866)\n",
    "* When, Why, and How (Not) to Use Them. [Cheveigne and Nelken, 2019](https://doi.org/10.1016/j.neuron.2019.02.039)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d0e49d-2e84-4298-b418-7fa54f19195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_filtering(trace_data, fs, filter_type='highpass', filter_order=4, filter_cutoff=1, method='butter'):\n",
    "    \"\"\"\n",
    "    Apply a Bessel or Butterworth filter to a time-series trace.\n",
    "\n",
    "    Args:\n",
    "        trace_data (numpy array or pandas Series): The data trace to be filtered. Can also be a pandas Series.\n",
    "        fs (float): Sampling frequency of the signal.\n",
    "        filter_type (str): Type of the filter ('lowpass', 'highpass', 'bandpass', 'bandstop').\n",
    "        filter_order (int): Order of the filter.\n",
    "        filter_cutoff (float or tuple): Cutoff frequency of the filter. For bandpass and bandstop filters, provide a tuple of (low, high).\n",
    "        method (str): Filter method ('bessel' or 'butter').\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Filtered trace.\n",
    "    \"\"\"\n",
    "    # Convert pandas Series to numpy array if needed\n",
    "    if isinstance(trace_data, pd.Series):\n",
    "        trace_data = trace_data.to_numpy()\n",
    "    \n",
    "    if method == 'bessel':\n",
    "        # Design Bessel filter\n",
    "        b, a = signal.bessel(\n",
    "            filter_order,         # Order of the filter\n",
    "            filter_cutoff,        # Cutoff frequency\n",
    "            filter_type,          # Type of filter\n",
    "            analog=False,         # Analog or digital filter\n",
    "            norm='phase',         # Frequency normalization\n",
    "            fs=fs                 # Sampling frequency\n",
    "        )\n",
    "    elif method == 'butter':\n",
    "        # Design Butterworth filter\n",
    "        b, a = signal.butter(\n",
    "            filter_order,         # Order of the filter\n",
    "            filter_cutoff,        # Cutoff frequency\n",
    "            filter_type,          # Type of filter\n",
    "            fs=fs                 # Sampling frequency\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Choose a 'method': 'bessel' or 'butter'\")\n",
    "\n",
    "    # Apply the filter\n",
    "    filtered_trace = signal.filtfilt(b, a, trace_data)\n",
    "\n",
    "    return filtered_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50615d-bf2d-4614-be10-f148e88a5c6c",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277eb658-3626-4e52-9992-ab5f1cbd37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_padding(trace_data, window_size):\n",
    "    \"\"\"\n",
    "    Apply padding to a Pandas Series or numpy array to handle edge effects for rolling operations.\n",
    "    \n",
    "    Args:\n",
    "        trace_data (pd.Series or np.ndarray): The data series or array to pad.\n",
    "        window_size (int): The size of the rolling window.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series or np.ndarray: Padded data series or array.\n",
    "    \"\"\"\n",
    "    # Convert to pandas Series if trace_data is numpy array\n",
    "    if isinstance(trace_data, np.ndarray):\n",
    "        trace_data = pd.Series(trace_data)\n",
    "    \n",
    "    # Apply padding\n",
    "    pad_width = window_size // 2\n",
    "    trace_padded = pd.concat([\n",
    "        pd.Series([trace_data.iloc[0]] * pad_width),\n",
    "        trace_data,\n",
    "        pd.Series([trace_data.iloc[-1]] * pad_width)\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    # Convert back to numpy array if the input was a numpy array\n",
    "    if isinstance(trace_data, np.ndarray):\n",
    "        return trace_padded.to_numpy()\n",
    "\n",
    "    return trace_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59b87ae-4ae0-4f4e-badf-8fc352ea06f5",
   "metadata": {},
   "source": [
    "# Detrend time-series data: plots\n",
    "\n",
    "Note that the LOESS/LOWESS method can be too aggressive for signals with low SNR or slow dynamics, and may remove information from the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdff48c-8309-4f5e-a96e-a2fb57cedc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiments to analyze\n",
    "experiments = (\"WF01\", \"WF02\")\n",
    "\n",
    "# Assuming paths['raw_data'] is the root directory for the files\n",
    "for dirpath, dirnames, filenames in os.walk(paths['raw_data']):\n",
    "    for filename in filenames:\n",
    "        # CSV files from specific experiments\n",
    "        if filename.startswith(experiments) and filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            basename = os.path.splitext(filename)[0]\n",
    "            timeseries = pd.read_csv(file_path)\n",
    "            timestamps = timeseries.iloc[:, 0]  # Select column with time/frame information\n",
    "            trace_data = timeseries.iloc[:, 1]  # Select column with signal information\n",
    "\n",
    "            window = int(np.round(len(trace_data)/10))\n",
    "\n",
    "            # Linear detrend\n",
    "            timeseries_linear_detrend = timeseries_detrend(trace_data, timestamps, method='linear', window=None)\n",
    "\n",
    "            # Exponential detrend\n",
    "            timeseries_exponential_detrend = timeseries_detrend(trace_data, timestamps, method='exponential', window=None)\n",
    "\n",
    "            # Rolling linear\n",
    "            timeseries_linregress_detrend = timeseries_detrend(trace_data, timestamps, method='rolling_linear', window=window)\n",
    "\n",
    "            # LOESS/LOWESS\n",
    "            timeseries_lowess_detrend = timeseries_detrend(trace_data, timestamps, method='lowess', window=window)\n",
    "            \n",
    "            # Plotting\n",
    "            fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(8, 8))\n",
    "\n",
    "            # Labels for all plots\n",
    "            axes = [ax1, ax2, ax3, ax4]\n",
    "            for ax in axes:\n",
    "                ax.set_xlabel(\"Timestamps\")\n",
    "                ax.set_ylabel(\"Signal\")\n",
    "\n",
    "            # ax1: Linear detrending\n",
    "            ax1.plot(timestamps, trace_data, label=f\"{basename} raw trace\")\n",
    "            ax1.plot(timestamps, timeseries_linear_detrend, label='Linear detrend')\n",
    "            \n",
    "            # Apply linear regression\n",
    "            slope, intercept, _, _, _ = stats.linregress(timestamps, trace_data)\n",
    "            linear_fit = slope * timestamps + intercept\n",
    "            ax1.plot(timestamps, linear_fit, label='Linear Regression', color='black', linestyle='--')\n",
    "            ax1.legend(loc='upper right')\n",
    "\n",
    "            # ax2: Exponential detrending\n",
    "            ax2.plot(timestamps, trace_data, label=f\"{basename} raw trace\")\n",
    "            ax2.plot(timestamps, timeseries_exponential_detrend, label='Exponential detrend')\n",
    "            \n",
    "            # Plot exponential fit\n",
    "            def exp_func(t, a, b):\n",
    "                return a * np.exp(-t * b)\n",
    "            popt, _ = curve_fit(exp_func, timestamps, trace_data, p0=(20, 0.005))\n",
    "            a, b = popt\n",
    "            exp_fit = exp_func(timestamps, a, b)\n",
    "            ax2.plot(timestamps, exp_fit, label='Exponential Fit', color='black', linestyle='--')\n",
    "            ax2.legend(loc='upper right')\n",
    "\n",
    "            # ax3: Rolling linear regression\n",
    "            ax3.plot(timestamps, trace_data, label=f\"{basename} raw trace\")\n",
    "            ax3.plot(timestamps, timeseries_linregress_detrend, label='Rolling Linear Detrend')\n",
    "            \n",
    "            # Compute and plot regression lines for each time window\n",
    "            n = len(trace_data)\n",
    "            for start in range(0, n, window):\n",
    "                end = min(start + window, n)\n",
    "                time_segment = timestamps[start:end]\n",
    "                trace_segment = trace_data[start:end]\n",
    "                if len(time_segment) > 1 and len(trace_segment) > 1:\n",
    "                    slope, intercept, _, _, _ = stats.linregress(time_segment, trace_segment)\n",
    "                    reg_line = slope * timestamps[start:end] + intercept\n",
    "                    ax3.plot(timestamps[start:end], reg_line, color='black', linestyle='--')\n",
    "            ax3.legend(loc='upper right')\n",
    "       \n",
    "            # ax4: LOESS/LOWESS\n",
    "            ax4.plot(timestamps, trace_data, label=f\"{basename} raw trace\")\n",
    "            ax4.plot(timestamps, timeseries_lowess_detrend, label='LOESS/LOWESS Detrend')\n",
    "    \n",
    "            # Plot LOESS/LOWESS fit\n",
    "            timeseries_np = np.vstack((timestamps, trace_data)).T\n",
    "            smoothed = lowess(trace_data, timestamps, frac=window/np.ptp(timeseries_np[:, 0]))\n",
    "            ax4.plot(smoothed[:, 0], smoothed[:, 1], color='black', linestyle='--', label='LOESS/LOWESS Fit')\n",
    "            ax4.legend(loc='upper right')\n",
    "            \n",
    "            # Show the plots\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save plots\n",
    "            fig.savefig(f\"{paths['plots']}/{filename}_detrending_examples.tif\", dpi=300)  # use '.svg' to save as vector image.\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f14a33-c670-422d-b81a-56d04042962c",
   "metadata": {},
   "source": [
    "# Power spectra: plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8867b1-c4c6-46ec-a847-208d729ec745",
   "metadata": {},
   "source": [
    "Power spectrum analysis applies a fast Fourier transform (FFT) to the variation of a particular signal to compute its frequency spectrum. FFT is based on the principle that any continuous periodic signal can be represented as the sum of sine waves, and vice versa.\n",
    "\n",
    "The FFT estimates the amplitude of each sine wave (the power) and can be plotted in the frequency domain. This plot is called power spectrum (RMS units) or power spectral density (PSD). In PSD, RMS units are divided by Hz. PSD can be calculated by different approaches such as periodogram or Welch method.\n",
    "\n",
    "Calculating the PSD is normally more useful for detecting noise ephys traces, but slow artifacts can also be present in slow optical recordings. This information is useful for properly filtering the signal afterward.\n",
    "\n",
    "* Scipy power spectral density. [Periodogram](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.periodogram.html) and [Welch](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch) \n",
    "\n",
    "* [Scipy spectogram](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html)\n",
    "\n",
    "**Note**: Remember to sample the signal at least twice its fastest frequency component of interest ([Nyquist criterion](https://en.wikipedia.org/wiki/Nyquist_rate)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea2610-51f2-4e27-a881-a322e02d0182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through files\n",
    "for dirpath, dirnames, filenames in os.walk(paths['raw_data']):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        # CSV files from specific experiments\n",
    "        if filename.startswith(experiments) and filename.endswith(\".csv\"):\n",
    "            basename = os.path.splitext(filename)[0]\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            timeseries = pd.read_csv(file_path)\n",
    "            timestamps = timeseries.iloc[:, 0]  # Select column with time/frame information\n",
    "            trace_data = timeseries.iloc[:, 1]  # Select column with signal information\n",
    "\n",
    "            # Apply detrend. For example: LOESS/LOWESS \n",
    "            trace_detrended = timeseries_detrend(trace_data, timestamps, method='lowess', window=300)\n",
    "            recording_length_s = 300\n",
    "            fs = len(trace_detrended)/recording_length_s\n",
    "            f, Pxx_den = signal.periodogram(trace_detrended, fs)\n",
    "            fig, ax = plt.subplots(figsize=(6,2))\n",
    "            ax.semilogy(f[1:], Pxx_den[1:])\n",
    "            ax.set_title(f\"{basename}\")\n",
    "            ax.set_xlabel('Frequency (Hz)')\n",
    "            ax.set_ylabel('PSD ($V^2$/Hz)')\n",
    "\n",
    "            # Save plots\n",
    "            fig.savefig(f\"{paths['plots']}/{filename}_power_spectra.tif\", dpi=300)  # use '.svg' to save as vector image.\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c8d0d-5ab6-4658-8470-f58d3ee329b2",
   "metadata": {},
   "source": [
    "# Filter time-series data: plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37d97b-b1cc-47cc-91d0-79475cd97024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through files\n",
    "for dirpath, dirnames, filenames in os.walk(paths['raw_data']):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        # CSV files from specific experiments\n",
    "        if filename.startswith(experiments) and filename.endswith(\".csv\"):\n",
    "            basename = os.path.splitext(filename)[0]\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            timeseries = pd.read_csv(file_path)\n",
    "            timestamps = timeseries.iloc[:, 0]  # Select column with time/frame information\n",
    "            trace_data = timeseries.iloc[:, 1]  # Select column with signal information\n",
    "\n",
    "            # Apply detrend. For example: LOESS/LOWESS \n",
    "            trace_detrended = timeseries_detrend(trace_data, timestamps, method='lowess', window=300)  \n",
    "\n",
    "            # Define sampling frequency\n",
    "            recording_length_s = 300\n",
    "            fs = len(timestamps)/recording_length_s \n",
    "\n",
    "            # Apply filters\n",
    "            # Bessel filter\n",
    "            trace_bessel_filter = timeseries_filtering(trace_detrended, fs, filter_type='lowpass', \n",
    "                                                       filter_order=4, filter_cutoff=fs/3, method='bessel')\n",
    "            \n",
    "            # Gaussian filter\n",
    "            trace_gaussian_filter = gaussian_filter1d(trace_detrended, sigma=3) \n",
    "            \n",
    "            # Butterworth filter\n",
    "            trace_butter_filter = timeseries_filtering(trace_detrended, fs, filter_type='lowpass', \n",
    "                                                       filter_order=4, filter_cutoff=fs/3, method='butter')\n",
    "\n",
    "            # Plotting\n",
    "            fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(12, 3), sharey=True)\n",
    "\n",
    "            # Labels for all plots\n",
    "            axes = [ax1, ax2, ax3, ax4]\n",
    "            for ax in axes:\n",
    "                ax.set_xlabel(\"Timestamps\")\n",
    "                ax.set_ylabel(\"Signal\")\n",
    "            \n",
    "            ax1.set_title(f\"{basename}{' Detrended'}\")\n",
    "            ax1.plot(timestamps, trace_detrended)\n",
    "\n",
    "            ax2.set_title(f\"{basename}{' Bessel filter'}\")\n",
    "            ax2.plot(timestamps, trace_bessel_filter)\n",
    "            \n",
    "            ax3.set_title(f\"{basename}{' Gaussian filter'}\")\n",
    "            ax3.plot(timestamps, trace_gaussian_filter)\n",
    "            \n",
    "            ax4.set_title(f\"{basename}{' Butterworth filter'}\")\n",
    "            ax4.plot(timestamps, trace_butter_filter)\n",
    "\n",
    "            # Show the plots\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save plots\n",
    "            fig.savefig(f\"{paths['plots']}/{filename}_filtering_examples.tif\", dpi=300)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94de24a-d499-477a-8e6e-9c60d37ef27e",
   "metadata": {},
   "source": [
    "# Smooth time-series data: plots\n",
    "\n",
    "Smoothing removes certain frequencies or noise of a time series to get the general trend. Basically, it averages points with their neighbors in a time series. Two of the most common approaches are:\n",
    "\n",
    "* Moving average. Values within the sliding window are averaged and slide through the [time-series pandas rolling](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html). \n",
    "* Kernel smoothing. Instead of a time window, weights of the Kernel function are used for averaging the sliding window. It can be implemented using pandas `rolling` and Scipy `win_type`. Different kernel functions lead to different results. For example, a kernel with a shape of a gaussian. [Documentation](https://docs.scipy.org/doc/scipy/reference/signal.windows.html).\n",
    "\n",
    "Since you need to apply a time window for smoothing, there will be missing data at the beginning and end of your time series due to the rolling window operations. To fix this, you can apply padding to ensure that these edges are handled appropriately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7001d-61bf-4a91-bcc8-b14ba9a5e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define window size and other parameters\n",
    "window_size = 10\n",
    "std = 10  # Standard deviation for Gaussian window\n",
    "\n",
    "# Loop through files\n",
    "for dirpath, dirnames, filenames in os.walk(paths['raw_data']):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        # CSV files from specific experiments\n",
    "        if filename.startswith(experiments) and filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            timeseries = pd.read_csv(file_path)\n",
    "            timestamps = timeseries.iloc[:, 0]  # Select column with time/frame information\n",
    "            trace_data = timeseries.iloc[:, 1]  # Select column with signal information\n",
    "            \n",
    "            # Convert to Pandas Series if necessary\n",
    "            if isinstance(trace_data, np.ndarray):\n",
    "                trace_data = pd.Series(trace_data)\n",
    "            if isinstance(timestamps, np.ndarray):\n",
    "                timestamps = pd.Series(timestamps)\n",
    "            \n",
    "            # Apply detrend. For example: LOESS/LOWESS \n",
    "            trace_detrended = timeseries_detrend(trace_data, timestamps, method='lowess', window=300) \n",
    "            trace_detrended = pd.Series(trace_detrended)\n",
    "            \n",
    "            # Apply padding\n",
    "            padded_detrended = timeseries_padding(trace_detrended, window_size)\n",
    "\n",
    "            # Moving average in Pandas\n",
    "            trace_rolling_avg = padded_detrended.rolling(window_size, center=True).mean()\n",
    "            \n",
    "            # Kernel smoothing with Gaussian window\n",
    "            kernel_window = signal.windows.gaussian(window_size, std=std)\n",
    "            # padded_trace_kernel = padded_detrended.rolling(window_size, center=True).mean()\n",
    "            padded_trace_kernel = padded_detrended.rolling(window_size, win_type=\"gaussian\", center=True).mean(std=std)\n",
    "            \n",
    "            # Trim the padded edges to match the original length\n",
    "            trace_kernel = padded_trace_kernel[window_size // 2: -window_size // 2]\n",
    "            timestamps_trimmed = timestamps[:len(trace_kernel)]  # Adjust timestamps length to match\n",
    "            \n",
    "            # Plotting\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 4), sharey=True)\n",
    "            \n",
    "            # Corrected signal\n",
    "            ax1.set_title('Corrected Signal')\n",
    "            ax1.plot(timestamps_trimmed, trace_detrended[:len(timestamps_trimmed)], label='Corrected Signal')\n",
    "            ax1.set_xlabel('Timestamps')\n",
    "            ax1.set_ylabel('Signal')\n",
    "            ax1.legend()\n",
    "            \n",
    "            # Moving average\n",
    "            ax2.set_title('Moving Average')\n",
    "            ax2.plot(timestamps_trimmed, trace_rolling_avg[window_size // 2: -window_size // 2], label='Moving Average')\n",
    "            ax2.set_xlabel('Timestamps')\n",
    "            ax2.set_ylabel('Signal')\n",
    "            ax2.legend()\n",
    "            \n",
    "            # Kernel smoothing\n",
    "            ax3.set_title('Kernel Smoothing')\n",
    "            ax3.plot(timestamps_trimmed, trace_kernel, label='Kernel Smoothing')\n",
    "            \n",
    "            # Plot the Gaussian window moving through the trace\n",
    "            for start in range(window_size // 2, len(trace_detrended) - window_size // 2, window_size):\n",
    "                end = start + window_size\n",
    "                if end > len(trace_detrended):\n",
    "                    end = len(trace_detrended)\n",
    "                # Extract current window position\n",
    "                current_kernel = kernel_window[:end-start]  # Adjust the kernel size to the window size\n",
    "                kernel_time = timestamps_trimmed[start:end]  # Time stamps for the current window\n",
    "                ax3.plot(kernel_time, current_kernel / current_kernel.max() * trace_kernel[start:end].max(), \n",
    "                         linestyle='--', color='black', alpha=0.5)\n",
    "            \n",
    "            ax3.set_xlabel('Timestamps')\n",
    "            ax3.set_ylabel('Signal')\n",
    "            ax3.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save plots\n",
    "            fig.savefig(f\"{paths['plots']}/{filename}_smoothing_examples.tif\", dpi=300)\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
